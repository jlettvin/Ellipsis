___Whither and whence visual photons
needs must uncertain be yet by lawful pattern ruled.
Photons are produced, scattered, reflected, refracted, diffracted,
incident, and aborbed by a retina in "bleaching" events.
Daylight photons result from solar blackbody emission
with notches from atmospheric absorption.
Surviving photons are scattered by atmosphere,
reflect off objects, refract through a cornea, diffract through a pupil,
and are absorbed by plural species of photoreceptors.
Each of these processes contribute to spectral transforms.

`comment.ignore||
___Axiom: a photon is emitted from a visual angle
orders of magnitude smaller than the visual angle
of a retinal photoreceptor.

___Photons are emitted from point sources.
Each photon has a specific energy when emitted (frequency and wavelength).
Each photon absorbed by a retinal photoreceptor started from such a point.
To be absorbed, a photon must have a wavelength between 390 and 720 nm.
The relative probability of retinal incidence is governed by
refraction and diffraction.
The relative probability of receptor absorption is governed by
the receptor absorption spectrum.

___The retina is effectively noise free.
No receptor signal is produced in a fully dark-adapted retina.
Individual photon bleaching events produce receptor signals
reference.Hecht.
For a given receptor species an absorption spectrum gives
the probability that a photon of a one wavelength will be absorbed relative to
the probability that a photon of another wavelength will be absorbed.

___Individual photons accumulate in interference patterns.
`

___Laws governing perceptual invariants such as contrast and color invariance
must arise from quantitative retinal photon absorption differentials
from a typical scene.
Historically, image synthesis depends on use of
RGB components usually produced by LEDs.
Notwithstanding LMS retinal cone species having similar spectral peaks,
images produced as if by a digital camera achromatic lens
with an Airy disk smaller than one pixel
are not suitable for analyzing images produced by a chromatic natural lens
and Airy disk always larger than a human photoreceptor.
The subject of this paper is production of synthetic image encoding
suitable for broad spectrum analysis of human visual invariants.

___Two transforms dominate retinal image formation;
corneal refraction and pupillary diffraction.
Corneal refraction is modelled by an affine expansion &propto; \(1/\lambda\)
where short wavelengths are expanded more than long wavelengths.
Pupillary diffraction is modelled by an Airy kernel convolution
where the kernel size is &propto; \(\lambda\).
In other words, for a white object on a black background
oberve a blue tinge ringing the object as seen through a magnifying glass and
a red tinge ringing it as seen in the Airy disk from a pinhole.

___Both of these transforms apply to mathematical models of images
formed from photons counting in the millions or billions.
The affine transform from refraction is modelled simply enough.
Analysis of diffraction and synthesis of suitable diffraction images
from very low to very high photon counts will be
the primary focus of this paper.
Images produced and encoded using these methods
will enable further research into how retinal processing achieves invariance.

==== Point Source Diffraction

`figure.Airy|Airy pattern|{width="378" height="378"}RGB.Airy.small.png`
___When a very large number of photons from a point source
pass through an aperture and then fall on a surface
they accumulate in a diffraction pattern called an Airy pattern `figure.Airy`.
This intensity pattern is the square of
the photon wave function `equation.wave`.
Photon densities are properly synthesized by summing the wave equations
for all points over all wavelengths and squaring the result.
`comment.ignore|ignore|
Through the principle of superposition,
Photons do not interact.
As individual photons from a point source accumulate into an image
they tend to accumulate as an Airy pattern.
The accumulation has the character of a wave.
`

___This intensity map is ruled by `equation.Airy`.
This formula calculates idealized continuous distribution
from which deviation is unmeasurable at high photon counts.
Discrete photons do not form a continuous set.
Nor does a grid of sensors in a focal plane in an eye or camera.
The zoomed "pixels" in `figure.Airy` illustrate a grid
for billions of RGB source photons for a centrally located point source.

___Close examination reveals that different wavelengths
contribute differentially to a pattern at different radii.
Photographic and visual colors are typically thought to operate using RGB.
The names (R)ed, (G)reen, and (B)lue, as wavelengths,
are typically thought to be related to color perception.
In fact, color perception is independent of wavelength
`reference.LettvinColorsOfThings`.
Scientific labelling for RGB in retinal photoreceptor absorption
is LMS for Long, Medium, and Short.
However, since photography and displays use RGB,
they will be used interchangeably.
^^^
^^^
^^^
^^^
^^^
^^^^^
`figure.2points|<br />2 white points|
{width="128" height="128"}
hyperacuity0.original.png`
`figure.2onretina|<br />Retinal image with a 1mm pupil|
{width="128" height="128"}
hyperacuity1.saturate.png`
___The retinal image of two white RGB point sources
incident on a human retina after traversing a 1mm pupil
appears as an inchoate blur incapable of being resolved
by Rayleigh criterion, Sparrow limit, or even
Nyquist sampling limit in a Fourier transform of intensity.

___Wavelength dependence in `figure.2onretina`
is even more apparent than for `figure.Airy`.
This is the character of image for narrow band RGB illumination.
This paper will explore the problem of forming
retinal equivalent incident photons using broadband illumination
and methods for producing suitable sensed images for
analyzing how sensory data for vision is presented.
Even in `figure.2onretina`, enough photons are present
to give the image a seemingly continuous character.

==== Low Photon Count Diffraction

<table align="left"><tr><td>
`figure.1photon|<br />1 photon|Airy.kernel.11.0000001.gif`
`figure.10photon|<br />10 photons|Airy.kernel.11.0000010.gif`
`figure.100photon|<br />100 photons|Airy.kernel.11.0000100.gif`
`figure.1000photon|<br />1000 photons|Airy.kernel.11.0001000.gif`
</td></tr><tr><td>
`figure.3photons|<br />3 photons|Airy.kernel.11.0000003.gif`
`figure.30photon|<br />30 photons|Airy.kernel.11.0000030.gif`
`figure.300photon|<br />300 photons|Airy.kernel.11.0000300.gif`
`figure.3000photon|<br />3000 photons|Airy.kernel.11.0003000.gif`
</td></tr></table>
___Suppose one views a 0.1mm emerald
on a black velvet background pad
on a brightly lit white counter.
The photon count contributed by the emerald is very low.
The observer's pupil is constricted by high ambient light
and the act of scrutinizing for detail.

___When photon flux is low, the Airy pattern becomes
more difficult to discern as can be seen in the models
of accumulations of single monochromatic photon events
in `figure.1photon` to `figure.3000photon`.

___As can be seen, even at 3000 photons from a point source
the Airy pattern is yet to assume the continuous character
achieved at much higher photon fluxes experienced
when observing less carefully constructed scenes in bright light.

___Vision still works fairly well at low light levels
so whatever explanation is made for vision
must account for the ability to convert patterns such as these
to good enough quality internal reconstructions of the scene.

___It is important to note that,
when point sources are eccentric from the center,
different wavelength photons refract and diffract to
different centers aligned radially from the center;
yet the perception of a polychromatic point is of a single point source.

==== Photons, Spectra, and Blackbodies

`figure.solar|Solar Spectrum (wikimedia commons)|
{width="256" height="256"}
Solar_Spectrum.png`
`figure.blackbody|Blackbody radiation
(visible wavelengths are within the white region of the figure.
The peak absorption of typical human photoreceptors are shown as
colored vertical lines)|
{width="256" height="256"}Blackbody.png`
`figure.incandescent|Light bulb
(at a lower blackbody temperature of 2800K,
longer wavelengths dominate unlike sunlight
where shorter wavelengths dominate)
|
{width="256" height="256"}Incandescent.png`
___Natural lighting is not divided into photons having
3 or 4 energy bands discussed in robotic vision literature.
Daylight spectra are considered continuous in that
no energies or wavelengths are forbidden.
Typically, ambient light is broad spectrum as in `figure.blackbody`.
Sunlight resembles the 6500K curve with atmospheric absorption.
An incandescent lightbulb peak temperature is 3695K which yields
a slope that appears to rise monotonically from the blue end to the red end.
The spectrum of `figure.incandescent` is
typical for a light bulb at 2800K.
When moving from sunlight into incandescent light
one does not perceive a change in colors.
The change of spectrum does not change the colors seen
but the size, shape, and spectral composition
have changed dramatically by the change in light source.
^^^
^^^^^
`comment.url|blackbody|
https://code.google.com/p/agpy/source/browse/trunk/agpy/blackbody.py`

`def.I_0|Peak intensity|I<sub>0</sub>`
___The two spectra of `figure.blackbody` and `figure.incandescent`
were produced with `equation.blackbody`.
Blackbody radiation is specified with two parameters,
T (degrees Kelvin), and visual angle (or amplitude).
`equation.blackbody2|Blackbody equation in &lambda;|
I(\lambda,T) =
\frac{2 h c^3}{\lambda^5}\frac{1}{exp{\left(\frac{h c}{\lambda k T}\right)}-1}
`
`equation.blackbody|Blackbody equation in &nu;|
I(\nu,T) =
\frac{2h\nu^{3}}{c^2}\frac{1}{exp{\left(\frac{h\nu}{kT}\right)}-1}
where:
h=Planck constant
c=speed of light in a vacuum
k=Boltzmann constant
&nu;=photon frequency
T=body temperature in Kelvin
`
___Other spectra like `figure.receptor` and `figure.camera`
are generated using short lists of coefficient triples (a,b,c).
Curves in both figures took one or two triples each.
This equation is used for convenient curve-fitting.
`equation.gaussian|Gaussian function|
Gauss(x) = a~exp{\left(-\frac{\left(x-b\right)^2}{2c^2}\right)}
`

`figure.receptor|Retinal receptor absorption|
{width="256" height="256"}Receptor.png`
`figure.camera|Camera pixel absorption|
{width="256" height="256"}Camera.png`
___A typical trichromat human has three cone photoreceptors L, M, and S
and one rod photoreceptor (X in `figure.receptor`).
Human photoreceptors
absorb photons having short wavelengths.
Absorptions of long wavelength photons have sharp relative cutoffs.
S cones absorb almost no photons at wavelengths above ~550nm.
M cones cut off at ~625nm, and L cone cuts off at ~710nm.
Note a curious increase of L and M cone absorption at shorter wavelengths.
All this indicates that wavelengths in a scene are not
as sharply divided into color planes
as is assumed in standard image processing.

___Vision identifies readiness of a resource by its color.
Regardless of ambient light, a ripe apple should look red.
In fact, it does when viewed under a blue sky, a green forest canopy,
a red sunset, or by sodium light having only
two yellow and one blue spectral line.
Redness of an apple does not depend on
presence of long wavelength photons.
This is color constancy as described
for perception under `figure.blackbody` and `figure.incandescent`.
^^^
^^^
^^^
^^^
^^^
^^^
^^^
^^^
^^^
^^^
^^^
^^^
^^^
^^^
^^^
^^^
^^^
^^^
^^^
^^^
^^^
^^^^^
`equation.Airy|Airy equation|I = I_0 \left({2 J_1(u) \over u}\right)^2`
`equation.uparam|Airy parameter|u = {2 \pi a q \over \lambda R}
where:
J_1 = Bessel function of the first kind
a = aperture radius
q = focal plane offset
&lambda; = photon wavelength
R = distance from aperture to focal plane
`
`equation.wave|Airy wave equation|A = A_0 {2 J_1(u) \over u}
where:
A_0 = \sqrt{I_0}
`
___Wave superposition rules when
multiple points are being projected onto an image plane.
Waves from all points are summed
and the result is squared to yield an intensity map (image).

`gnuplot.Airy|Airy(x,y)|
{width="256" height="256"}
radius(a,x,y)=pi*sqrt((a*x)**2+(a*y)**2);
wave(a,x,y)=2*besj1(radius(a,x,y))/(radius(a,x,y));
Airy(a,x,y)=wave(a,x,y)**2;
cubeAiry(a,x)=10*Airy(a,x,0)*(a*x)**3;
set xrange[-4.22:4.22]; set yrange[-4.22:4.22]; set zrange[0:1];
set isosamples 101,101; set pm3d at b; splot Airy(1,x,y);
`

___The conditions under which this occurs are special.
An achromatic lens is required.

___The straight lines predicted by optics between this origin
identify the center of a probability distribution at the destination.
The relative probability of a photon of specific energy from a specific source
being absorbed within a specific tile in a grid of a tiled surface
is calculated by integrating the infinitesimal probabilities over the tile.
^^^
^^^
^^^
^^^
^^^
^^^
^^^
^^^
^^^
^^^
^^^
^^^
^^^
^^^
^^^
^^^
^^^
^^^
^^^
^^^
^^^
^^^
^^^
^^^
^^^
^^^
^^^
^^^
^^^
^^^
^^^
^^^
^^^^^
==== Retinal Photoreceptor Species Mosaic
`figure.mosaicL|Mosaic L cones|{width="241" height="241"}speciesL.png`
`figure.mosaicM|Mosaic M cones|{width="241" height="241"}speciesM.png`
`figure.mosaicS|Mosaic S cones|{width="241" height="241"}speciesS.png`
^^^^
`make.mosaic|Create the model species mosaic|php species.php`
`figure.mosaic|Species Mosaic|{width="241" height="241"}speciesLMS.png`

`reference.introdens|receptor densities|
author  = Christine A. Curcio
etal    = Christine A. Curcio and Kenneth R. Sloan
journal = Visual Neuroscience
volume  = 9
number  = 02
year    = 1992
month   = August
pages   = 169-180
URL     = http://www.cvrl.org/database/text/intros/introdens.htm`
`reference.SconeDistribution|Seeing with S Cones|
author  = David J. Calkins
title   = Seeing with S Cones
journal = Progress in Retinal and Eye Research
volume  = 20
number  = 3
pages   = 255-287
year    = 2001
`
`listing.species|Generating the mosaic|{align="right"}species.php`

___A human trichromat has four photoreceptor species
whose proportion and distribution vary in individuals
(`reference.introdens`, `reference.SconeDistribution`).
Our synthetic images
are consistent with in vivo data but use a rectangular grid.

___Either L cones or M cones dominate a macula.
Scarce S cones don't appear within 100&micro;M of center.
Rods appear in the outer macula where they
increase to 100% population beyond.

___As shown in `figure.mosaicL`-`figure.mosaicS`,
effective images for color planes have lacunae.
This paper predicts absorption events in full-spectrum scenes.

___Mosaic images are generated by PHP code `listing.species`.
`table.photoreceptors` is typical in human trichromats.
^^^^
`table.photoreceptors|Photoreceptor Species|
L|photoreceptors (cones shown as red)|~566nm peak absorption
M|photoreceptors (cones shown as green)|~533nm peak absorption
I|photoreceptors (rods shown as cyan)|~498nm peak absorption
S|photoreceptors (cones shown as blue)|~433nm peak absorption
`
^^^^^
`reference.LettvinColorsOfThings|The Colors Of Things|
author        = Jerome Y. Lettvin et al
etal          = Lettvin et al
title         = The Colors Of Things
month         = September
journal       = Scientific American
year          = 1986
volume        = 255.3
pages         = 84-92
`

==== Spectral Encoding Constraints
___A spectrum, as conceived of here, is a curve in \(\lambda\)
to which discrete probability data points may be fitted.
Important levels and inflection points must be preserved by
conversion back and forth between continuous curve and discrete vector form.
An image maps relative probabilities of photon events.
In the proposed system, probabilities are calculated from
vectors of equidistant values of \(\lambda\).
Each probability value of the vector represents the combined probability
at all values of \(\lambda\) along the binning interval
from halfway points between values specified in the vector.

___The relative probability of a photon event
at wavelength \(\lambda\) at point (x1,y1) due to one at point (x0,y0)
is the product of all probabilities along all probable pathways.
Calculation involves converting all continuous forms of spectra
to identically binned \(\lambda\) intervals and
multiplying all the probabilities found in a bin.

___A new method of encoding spectra for a given retinal pixel is needed.
The encoding must support calculation of relative probabilities of absorption.
It must support expression of blackbody radiation, monochromatic sources,
polynomial spectral shapes, and simple discrete vectors.
It must serve for use with any spectral operation used to synthesize an image.

___Retinal photoreceptors respond to photons across the entire visual spectrum.
The retinal response to a scene lit by sunlight
is modelled by computing the dot product of the discrete spectrum
presented to a photoreceptor with its absorption spectrum.
The point of this paper is to compute that dot product and
show the effect this has on each of the cone species mosaics
and on the combined mosaics.
No knowledge of wavelength survives.

___For the vast majority of spectra, it is sufficient to specify
a source as either a set of blackbodies or as a set of gaussians.
Usually a single blackbody is sufficiently specified
as an amplitude and a temperature (two parameters).
Usually a single gaussian is sufficiently specified
as an amplitude, a peak &lambda;, and a width (three parameters).

___Synthetic images are produced by summing wave equations
and squaring the result, so it is convenient to use
the square root of peak intensity as the amplitude.
An image can be fully specified with spectral precision
from pixels composed from their spectral components.

___Pixels locations may be either specified on pixel groups
randomly scattered over the image, or as raster images where
the location is implied by its position in the raster line set.

___The former permits a full lower-quality image to be delivered early
with improving fidelity as more pixels arrive.
The latter requires full delivery of all pixels before
the full image may be seen.
In the former case, a spectral specification is given
followed by a sequence of (x,y) pixel coordinates.
A 4096x4096 pixel image can use 12 bits per dimension
or 3 bytes per pixel.
First priority of presentation should be given to
generating a neutral background.
Second priority should be given to larger differences across boundaries.
Last priority should be given to field filling operations.

___Digital cameras are unable to produce images of this type
since they are restricted to sampling 3 narrow spectral bands.
Older photographs are also unable to produce these images
for similar reasons.
The only feasible manner of production of test images
suitable for analysis of vision is synthesis.

___As will be shown, acceptable synthetic images can be produced
and their effects on retinal photreceptors properly modelled.

^^^
^^^
^^^
^^^
^^^
^^^
^^^
^^^
^^^
^^^
^^^
^^^
^^^
^^^
^^^
^^^
^^^
^^^
^^^
^^^
^^^
^^^^^
